{"cells":[{"cell_type":"code","execution_count":1,"id":"8381fdeb-db74-4940-b570-6d045ba740e5","metadata":{"id":"8381fdeb-db74-4940-b570-6d045ba740e5","outputId":"209d9c74-5035-4114-ea51-efcf751f78b9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730741171876,"user_tz":-180,"elapsed":4328,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["pip install nltk transformers"]},{"cell_type":"code","execution_count":2,"id":"cf158bc8-e431-4c0a-b1e4-1d3f002dc662","metadata":{"id":"cf158bc8-e431-4c0a-b1e4-1d3f002dc662","outputId":"b3978fc4-c63e-41f7-bda6-1832d059520d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730741177506,"user_tz":-180,"elapsed":5043,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}],"source":["pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"]},{"cell_type":"code","execution_count":3,"id":"5ab7baaf-a04e-4dbf-834e-51cc3a856084","metadata":{"id":"5ab7baaf-a04e-4dbf-834e-51cc3a856084","outputId":"20afa94c-394e-44d2-822a-40d4b47e84b3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730741191170,"user_tz":-180,"elapsed":13666,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["import torch\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from torch.utils.data import DataLoader, TensorDataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import time\n","from tqdm import tqdm\n","import nltk\n","from nltk.translate.gleu_score import sentence_gleu\n","import numpy as np\n","\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":4,"id":"e4001b32-1e0c-482b-b391-550b64ecbca7","metadata":{"id":"e4001b32-1e0c-482b-b391-550b64ecbca7","executionInfo":{"status":"ok","timestamp":1730741191948,"user_tz":-180,"elapsed":780,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["# Load dataset\n","df = pd.read_csv(\"Cleaned_Lang8.csv\", header=None)\n","df.columns = [\"0\", \"1\"]\n","\n","# Split data into train and eval sets\n","train_df, eval_df = train_test_split(df, test_size=0.3, random_state=9, shuffle=True)\n","\n","# Convert to lists\n","train_texts = train_df[\"0\"].tolist()\n","train_labels = train_df[\"1\"].tolist()\n","eval_texts = eval_df[\"0\"].tolist()\n","eval_labels = eval_df[\"1\"].tolist()"]},{"cell_type":"code","execution_count":16,"id":"fd06c004-3389-4a50-8454-ad60317a7212","metadata":{"id":"fd06c004-3389-4a50-8454-ad60317a7212","executionInfo":{"status":"ok","timestamp":1730741404993,"user_tz":-180,"elapsed":762,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["# Setting batch size and number of epochs of each run\n","batch_size = 16\n","epochs = 5"]},{"cell_type":"code","execution_count":17,"id":"bdc7c433-5aa4-49da-9866-b0a658c11e7c","metadata":{"scrolled":true,"id":"bdc7c433-5aa4-49da-9866-b0a658c11e7c","executionInfo":{"status":"ok","timestamp":1730741458525,"user_tz":-180,"elapsed":53533,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")  # Replace \"t5-base\" with your desired model\n","\n","# Tokenize and encode the training and evaluation sets\n","train_encodings = tokenizer(train_df[\"0\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","train_labels = tokenizer(train_df[\"1\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","\n","eval_encodings = tokenizer(eval_df[\"0\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","eval_labels = tokenizer(eval_df[\"1\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":18,"id":"3f2e174e-2fd7-4d24-831f-237e5c664d3b","metadata":{"id":"3f2e174e-2fd7-4d24-831f-237e5c664d3b","executionInfo":{"status":"ok","timestamp":1730741458526,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["# Prepare TensorDatasets\n","train_dataset = TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], train_labels[\"input_ids\"])\n","eval_dataset = TensorDataset(eval_encodings[\"input_ids\"], eval_encodings[\"attention_mask\"], eval_labels[\"input_ids\"])\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","eval_loader = DataLoader(eval_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":19,"id":"11532caa-061e-49e5-9f32-78a39b1047f9","metadata":{"id":"11532caa-061e-49e5-9f32-78a39b1047f9","outputId":"d65bcbea-2c27-41ff-f66c-5c2a39a3a392","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730741462519,"user_tz":-180,"elapsed":3995,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":19}],"source":["# Load model\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n","# Move the model to the mps device\n","model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":20,"id":"d61418a1-83c5-4182-8be3-6ccdf71f74ea","metadata":{"id":"d61418a1-83c5-4182-8be3-6ccdf71f74ea","executionInfo":{"status":"ok","timestamp":1730741462519,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["# Set up optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)"]},{"cell_type":"code","execution_count":21,"id":"fbddced3-48fb-4398-a4e7-a147183f6beb","metadata":{"id":"fbddced3-48fb-4398-a4e7-a147183f6beb","executionInfo":{"status":"ok","timestamp":1730741462519,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jsom","userId":"11727936416248040990"}}},"outputs":[],"source":["def train_model(model, train_loader, optimizer, epochs, startepoch=0, checkpoint_path=None):\n","    # Create the mps device\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    # Set the mode of the model to training mode\n","    model.train()\n","    start_time = time.time()\n","\n","    for epoch in range(startepoch, epochs):\n","        print(f\"Epoch {epoch + 1}/{epochs}\")\n","        total_loss = 0\n","\n","        for batch in tqdm(train_loader):\n","            optimizer.zero_grad()\n","            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","\n","            # Forward pass\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","\n","            # Backward pass\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Average Loss: {avg_loss:.4f}\")\n","\n","        # Save a checkpoint after each epoch, if checkpoint path is provided\n","        if checkpoint_path:\n","            torch.save({\n","                'epoch': epoch + 1,  # Save the current epoch\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': avg_loss,\n","            }, checkpoint_path)\n","            print(f\"Checkpoint saved at epoch {epoch + 1}\")\n","\n","    end_time = time.time()\n","    print(f\"Training completed in {(end_time - start_time) // 3600}h {(end_time - start_time) % 3600 // 60}m {(end_time - start_time) % 60}s\")\n"]},{"cell_type":"code","execution_count":null,"id":"e9cdba8a-77af-4396-b9b3-995d85cac4fe","metadata":{"id":"e9cdba8a-77af-4396-b9b3-995d85cac4fe","outputId":"df7522d4-a4dd-4dab-82e8-1a6790d839db","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8750/8750 [2:11:44<00:00,  1.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average Loss: 0.1094\n","Checkpoint saved at epoch 1\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[" 78%|███████▊  | 6833/8750 [1:43:01<28:53,  1.11it/s]"]}],"source":["# Initial train of the model\n","train_model(model, train_loader, optimizer, epochs, 0, \"t5model_checkpoint.pth\")"]},{"cell_type":"code","execution_count":null,"id":"fa48ef0a-1dc8-44e9-bed5-cb67454917da","metadata":{"id":"fa48ef0a-1dc8-44e9-bed5-cb67454917da"},"outputs":[],"source":["def evaluate_model_with_gleu(model, eval_loader, tokenizer):\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model.to(device)\n","    model.eval()\n","    gleu_scores = []\n","\n","    start_time = time.time()\n","\n","    with torch.no_grad():\n","        for batch in tqdm(eval_loader):\n","            # Move tensors individually to device\n","            input_ids = batch[0].to(device)\n","            attention_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","\n","            # Generate predictions\n","            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n","\n","            # Decode predictions and references\n","            predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n","            references = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n","\n","            # Calculate GLEU for each sentence\n","            for pred, ref in zip(predictions, references):\n","                ref_tokens = [ref.split()]\n","                pred_tokens = pred.split()\n","                gleu_score = sentence_gleu(ref_tokens, pred_tokens)\n","                gleu_scores.append(gleu_score)\n","\n","    avg_gleu_score = np.mean(gleu_scores)\n","    end_time = time.time()\n","\n","    print(f\"Evaluation completed in {(end_time - start_time) // 3600}h {(end_time - start_time) % 3600 // 60}m {(end_time - start_time) % 60}s\")\n","    print(f\"Average GLEU Score: {avg_gleu_score:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"fb7889df-c9e4-44fc-a7c9-594f8e6d1587","metadata":{"id":"fb7889df-c9e4-44fc-a7c9-594f8e6d1587"},"outputs":[],"source":["# Evaluate the model\n","evaluate_model_with_gleu(model, eval_loader, tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"8904634e-d929-44de-856a-3fa6d6cfb65a","metadata":{"id":"8904634e-d929-44de-856a-3fa6d6cfb65a"},"outputs":[],"source":["def predict(texts, model, tokenizer, max_length=128):\n","    # Ensure the model is in evaluation mode\n","    model.eval()\n","\n","    # Device configuration\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model.to(device)\n","\n","    # Tokenize the input text(s)\n","    encodings = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n","    input_ids = encodings[\"input_ids\"].to(device)\n","    attention_mask = encodings[\"attention_mask\"].to(device)\n","\n","    # Generate predictions\n","    with torch.no_grad():\n","        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=max_length)\n","\n","    # Decode predictions to text\n","    predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n","    return predictions"]},{"cell_type":"code","execution_count":null,"id":"6586e3aa-e15f-4a28-80cd-8455da448be2","metadata":{"id":"6586e3aa-e15f-4a28-80cd-8455da448be2"},"outputs":[],"source":["texts = [\"These is a example sentence that needs correction.\",\n","         \"Another sentence for tests gramar corection.\"]\n","predicted_texts = predict(texts, model, tokenizer)\n","\n","for i, prediction in enumerate(predicted_texts):\n","    print(f\"Original: {texts[i]}\")\n","    print(f\"Corrected: {prediction}\")"]},{"cell_type":"code","execution_count":null,"id":"f728ad72-1967-4594-8e0e-4f3a3c5b1ebb","metadata":{"id":"f728ad72-1967-4594-8e0e-4f3a3c5b1ebb"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[{"file_id":"17nNyGhs_d-h-_wfZz5GjweQYfAGK8A4m","timestamp":1730740692903}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}